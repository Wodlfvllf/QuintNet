# QuintNet TensorParallelism

A high-performance PyTorch library for tensor parallelism in distributed deep learning. Designed for seamless integration with existing PyTorch workflows while providing efficient scaling across multiple GPUs.

Data Parallelism:     Model Parallelism:      Tensor Parallelism:
â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”
â”‚  M  â”‚  M  â”‚  M  â”‚   â”‚  L1 â”‚ â”‚  L2 â”‚   â†’    â”‚ L â”‚ L â”‚ L â”‚ L â”‚
â”‚  o  â”‚  o  â”‚  o  â”‚   â”‚  L2 â”‚ â”‚  L3 â”‚        â”‚ 1 â”‚ 1 â”‚ 1 â”‚ 1 â”‚
â”‚  d  â”‚  d  â”‚  d  â”‚   â”‚  L3 â”‚ â”‚  L4 â”‚        â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜
â”‚  e  â”‚  e  â”‚  e  â”‚   â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜        Split within layer
â”‚  l  â”‚  l  â”‚  l  â”‚   Sequential             Parallel execution
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜   execution
Different data        Different layers        Same layer split


## âœ¨ Key Features

- **ğŸš€ One-Line Integration**: Convert any PyTorch model with a single function call
- **âš¡ Optimized Communication**: Custom autograd functions for minimal overhead
- **ğŸ”§ Modular Architecture**: Clean, maintainable codebase with clear separation of concerns  
- **ğŸ“ˆ Linear Scaling**: Efficient memory and compute distribution across GPUs
- **ğŸ›¡ï¸ Production Ready**: Robust error handling and comprehensive testing

## ğŸš€ Quick Start

```python
import torch.distributed as dist
from QuintNet.TensorParallelism import apply_tensor_parallel

# Initialize distributed training
dist.init_process_group(backend="nccl")

# Convert your model to tensor parallel
model = apply_tensor_parallel(model, tp_size=4)

# Continue training as usual - no code changes needed!
```

```bash
# Run distributed training
torchrun --standalone --nproc_per_node=4 your_training_script.py
```

## ğŸ—ï¸ Architecture Overview

```
QuintNet/TensorParallelism/
â”œâ”€â”€ comm_ops.py          # Distributed communication primitives
â”œâ”€â”€ layers.py            # Tensor parallel layer implementations  
â”œâ”€â”€ rewrite.py           # Automatic model conversion utilities
â”œâ”€â”€ processgroup.py      # Process group management
â””â”€â”€ utils.py             # Optional helper functions
```

### Core Components

| Component | Purpose | Key Classes |
|-----------|---------|-------------|
| **Communication Ops** | Distributed primitives with autograd support | `All_Gather`, `All_Reduce`, `ReduceScatter` |
| **Parallel Layers** | Drop-in replacements for standard layers | `ColumnParallelLinear`, `RowParallelLinear` |
| **Model Rewriter** | Automatic model conversion | `apply_tensor_parallel()` |
| **Process Groups** | Multi-GPU coordination | `ProcessGroupManager` |

## ğŸ“Š Performance Benefits

- **Memory Efficiency**: 4x memory reduction with 4-GPU tensor parallelism
- **Communication Optimized**: Minimal overhead with fused operations
- **Scalable**: Linear performance scaling up to model capacity limits

## ğŸ”§ Installation & Setup

```bash
# Prerequisites
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Clone and setup
git clone <repository-url>
cd QuintNet
```

## ğŸ“š Documentation

- **[Complete Documentation](DOCUMENTATION.md)** - Detailed API reference and advanced usage
- **[Examples](examples/)** - Working examples and tutorials
- **[Performance Guide](docs/performance.md)** - Optimization tips and benchmarks

## ğŸ¯ Use Cases

- **Large Language Models**: Efficient training of transformer architectures
- **Computer Vision**: Scaling ResNets, Vision Transformers, and CNNs
- **Research**: Rapid prototyping of distributed training strategies
- **Production**: Reliable multi-GPU training pipelines

## ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

### Development Setup
```bash
# Install development dependencies
pip install -r requirements-dev.txt

# Run tests
python -m pytest tests/

# Code formatting
black . && isort .
```

## ğŸ“„ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file for details.

## ğŸ™‹â€â™‚ï¸ Support

- **Issues**: [GitHub Issues](https://github.com/your-org/QuintNet/issues)
- **Discussions**: [GitHub Discussions](https://github.com/your-org/QuintNet/discussions)
- **Documentation**: [Full Documentation](DOCUMENTATION.md)

## ğŸ† Acknowledgments

Built with â¤ï¸ for the PyTorch distributed training community.

---

**Ready to scale your models?** Check out our [Complete Documentation](DOCUMENTATION.md) to get started!